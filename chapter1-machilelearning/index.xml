<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Data Science Notes</title>
    <link>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/</link>
    <description>Recent content in Machine Learning on Data Science Notes</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Linear Regression</title>
      <link>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/1_linear_regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/1_linear_regression/</guid>
      <description>Regression is fitting a line to our data; Discovering the hidden relationship between input and output.
Univariate linear regression  Linear regression with one independent variable (or feature). a training example: $(x^{(i)},y^{(i)})$, where $i=1,\ldots,m$. $m$ represents the number of training examples. $X$ - space of input variables; $Y$ - space of output variables $h: X \mapsto Y$, where $h$ is a hypothesis. Hypothesis: $h_{\theta} (x)=\theta_0 + \theta_1 x $; Shorthand notation: $h(x)$.</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/2_logistic_regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/2_logistic_regression/</guid>
      <description>Coursera Notes:
Classification  Email: spam / not spam Online transactions: Fraudulent (yes/no) Tumor: Malignant/Benign ?  $y=0$: negative Class (Benign tumor) $y=1$: positive class (Malignant)   Threshold classifier output $h_{\theta}$ at 0.5:  if $h_{\theta} \geq 0.5$, predict $y=1$ if $h_{\theta} &amp;lt; 0.5$, predict $y=0$   Classification $y=0$ or $y=1$. But if we use linear regression formula, $h_{\theta}(x)$ can be &amp;lt;0 or &amp;gt;1 Logistic regression model: want $0 \leq h_{\theta} \leq 1$ Sigmoid function $g(z)$: output values range from 0 to 1 \begin{equation} g(z)=\frac{1}{1+\exp^{-z}} \end{equation} set, $z=\Theta^T x$ Hypothesis: \begin{equation} h_{\theta} (x) = \frac{1}{1+\exp^{-\Theta^T x}} \end{equation}  Interpretation of hypothesis output  $h_{\theta}(x)$ is the estimated probability that $y=1$ on input $x$ $h_{\theta}(x)=0.</description>
    </item>
    
    <item>
      <title>Artificial neural networks</title>
      <link>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/3_ann/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/3_ann/</guid>
      <description>Human brain has approximately 86 billion neuros which are connected to each other via synapses. Neurons receive signals from other neurons via their dendrites and transmit their output through their axons. A neuron only fires if the total signal received exceeds a certain threshold value. &amp;ldquo;Neural pathways are strengthened every time that they are used&amp;rdquo; -Donald hebb. If two neurons fire together, their connection is enhanced. The strength is referred to as the weight.</description>
    </item>
    
    <item>
      <title>Sequence Modeling</title>
      <link>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/6_sequence_modeling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://bharathravu.github.io/data-science-notes/chapter1-machilelearning/6_sequence_modeling/</guid>
      <description>LSTM is awesome, but not good enough Transformers: how and why $f(X) \approx y$, where $f$ is the model, X is the input and $y$ is the outcome/prediction Sequence Modeling is a problem $f:\mathbb{R}^d \mapsto \mathbb{R}$, $\mathbb{R}^d$ contains fixed size $d$ vectors can not represent documents a fixed size vector Documents are of various lengths Not aware of any linear algebra that works on variable dimensionality Classic way: bag of words Order matters: &amp;ldquo;work to live&amp;rdquo; vs &amp;ldquo;live to work&amp;rdquo;; Both score same.</description>
    </item>
    
  </channel>
</rss>